# 27/12/2023

Ngga terasa ternyata udah 2 hari gw ngga megang projek, yah karena alin pulang dan gw sibuk refreshin nonton anime bareng sih, worth it.

Sekarang lanjut lagi deh, semenjak ngejain projek ini, gw ngerasa optimasi kode itu penting banget sih, dari mikirin memori, banyaknya pemanggilan, waktu pemrosesan dan sebagainya. Kemaren2 bikin lemot karena banyak banget pemanggilan database yang diulang2 walaupun data yang dipanggil sama2 aja. Setelah gw pake-in caching yang lebih akurat, atau lebih bener, waktu pemrosesannya berkurang drastis, tapi belom dicoba di algoritma genetikanya sih, baru nyoba di salah satu fungsi, fungsi repair.

Ada beberapa konsep yang harus gw inget2 sih, caching, parallezing, profiler.
Dari sini juga, gw mulai ngeh kalo pemanggilan database itu cukup resource instensive ya.
--------------

Ohiya karena gw rada ngubah struktur gene, mungkin ada beberapa fungsi yang bisa diubah dan dibikin lebih efisien, khususnya yang mengandalkan pemanggilan data langsung. Karena sekarang beberapa bisa dipanggil via gene langsung, jadi keknya bisa dibikin lebih fleksibel lagi dengan ngganti pemanggilan via kelas, jadi via gene langsung aja.

--------------

Wew proses repair yang awalnya 4 menit buat 50 populasi, menurun jadi 14 detik, terus turun lagi jadi 1.4 detik, hmmm itu berapa persen peningkatan ya? Hmmm, mungkin kah pembangkitan populasi bisa dipersingkat lagi? Sekarang kurang lebih makan waktu 24 detik buat bangkitin populasi.

---------------

Sempet nyoba bandingin ulang pembangkitan populasi, ternyata kecepatan pararel dan serial bukan tergantung banyaknya populasi sih, tapi lamanya waktu yang diperlukan, bukan bagi2 proses jadi pararel cukup makan waktu, kalo pembagian proses itu justru lebih lama dari pembangkitan beberapa populasi via serial, maka jadi ngga sepadan gitu. Hmm bisa jadi pertimbangan buat projek kedepannya. Kalo semisal pembangkitan populasi lebih kompleks, mungkin make metode pararel bakal lebih efisien, tapi karena yang dipake sekarang cukup simpel, jadi malah bikin makin lama.

tapi... selama ngodong, walau gw tau beberapa konsep baru, gw malah jadi ngga terlalu ingat ama kode2 yang gw buat, karena ya mayoritas rekomendasi dari autopilot, jadi kalo misal suatu saat nanti gw ngga ada akses ke autopilot, gw literally bakal bener2 kebingungan bahkan untuk nulis ulang kode yang sebelumnya gw paham, karena gw jadi cuman liat bentuk umumnya doang, ngga apal apa command2 yang gw pake. Mungkin nanti ketika semua udah selesai, bakal gw pelajarin ulang lebih dalam lagi deh . . .

Population size: 1024
Serial time: 28.783354099999997
Parallel time: 46.52939769999648
Speedup: 0.6186057744736759
Serial is faster with time difference of:  17.746043599996483

----------------------------------
Population size: 2048
Serial time: 69.76994240000204
Parallel time: 61.14334669998789
Speedup: 1.141088052349216
Parallel is faster with time difference of:  8.62659570001415

----------------------------------
Population size: 4096
Serial time: 66.03537579999829
Parallel time: 124.72658830000728
Speedup: 0.5294410494189268
Serial is faster with time difference of:  58.69121250000899

----------------------------------
Population size: 8192
Serial time: 129.1994040999998
Parallel time: 355.3302901999996
Speedup: 0.363603688352263
Serial is faster with time difference of:  226.13088609999977

----------------------------------

Reminder juga, kalo objek mutable (seperti list dan sebagainya) dijaddin argumen kedalam fungsi, terus objek tersebut dimodif didalemnya (kayak ngubah angka dan urutan), maka objek tersebut juga ikut keedit juga diluarnya, jadi mesti bikin salinan dulu didalemnya kalo emang ngga mau keubah tanpa sengaja, kecuali kalo cuman bikin kalkulasi atau return data baru sih.

Berarti karena fungsi mutasi gw ngga pake deepcopy,
```python
class SwapMutation(BaseMutation):
    def __init__(self):
        super().__init__("SwapMutation")
    
    def __call__(self, chromosome: Chromosome):
        # Randomly select a gene
        gene1 = random.choice(chromosome)
        # Randomly select another gene
        gene2 = random.choice(chromosome)
        # Swap the time slot and the assistant
        gene1.time_slot, gene2.time_slot = gene2.time_slot, gene1.time_slot
        gene1.assistant, gene2.assistant = gene2.assistant, gene1.assistant

        return chromosome
```
		
gw ngga perlu assign variable baru kayak gini dong?
```python
# Mutation
        child1 = self.__mutation(child1)
        child2 = self.__mutation(child2)
        mutation_time = time.time() - start - selection_time - crossover_time
        self.log[iteration]["mutation_time"] += mutation_time
```

jadi tinggal gini aja???
```python
# Mutation
        self.__mutation(child1)
        self.__mutation(child2)
        mutation_time = time.time() - start - selection_time - crossover_time
        self.log[iteration]["mutation_time"] += mutation_time

        # Repair
        self.__repair(child1)
        self.__repair(child2)
```

Apakah ini salah satu optimasi hmm

Simpelnya buat objek yang sekiranya bakal dipake lagi atau dipake ulang dan butuh data origal untuk proses lain pake deepcopy, kayak crossover.
Di proses kita butuh make data chromosome untuk bikin 2 anak, dan anak2 itu perlu diproses selanjutnya tanpa ingin mengubah data original parent, maka pake deepcopy deh, duh bingung juga kalo dijelasin . . .

Pokoknya ini juga jadi salah satu konsep yang mesti gw dalemin, yaitu referensi mutable data . . .
Salah2 malah bakal bikin data kacau.

-------------------------------------------------------

Pantesan kemaren makin lama dan lama njir buat tiap iterasinya, ternyata untuk tiap iterasi jumlah populasi yang ditambahin semakin bertambah, atau bahkan mendouble, ternyata diakhir tiap iterasi populasi baru selalu ditambahin ke populasi lama. Gw ngga liat kode penambahan populasi kecuali penambahan elitism sih, apakah kendalanya disitu? Hmm, salah gw juga sih terlalu percaya ama copilot tanpa review2 tiap kode, atau bisa dibilang tanpa bener2 paham ama apa yang dia tulis.