# 24/12/2023

Kemaren2 udah ada progress sih, tapi gw taro disini aja biar ngga ribet mikirinnya.
Hmmm, intinya gw nyoba2 nambah prosess pararel sih, awalnya rada ribet, mungkin karena gw ngga ngerti strukturnya. Tapi setelah coba2 akhirnya bisa, walau mayoritas dapet bantuan dari AI sih. Ini catetan yang gw tulis didalem jupyter ->

#### Pararel and Serial version comparison

Setelah dicoba, pada awalnya versi pararel lebih lambat dari versi serial, khususnya pada ukuran populasi rendah. Sekiranya antara 1 hingga 100 populasi, versi serial lebih cepat dari pada yang pararel. Tapi ketika ukuran populasi meningkat, setidaknya diatas 100, kecepatan versi pararel mulai mengungguli versi serial. Perbedaan yang dihasilkan juga cukup signifikan, pada saat populasi mencapai 512, versi pararel 1.5 kali lebih cepat dari versi serial. Apakah itu cukup signifikan? Mungkin kita coba lagi dengan ukuran populasi yang lebih besar, misal 1024 atau 2048. Sementara itu, ini adalah hasil perbandingan dari ujicoba sebelumnya. Untuk keterangan, ukuran chromosome untuk tiap populasi adalah 288.

| Population Size | Serial | Pararel | Pararel Speedup |
| --------------- | ------ | ------- | --------------- |
| 2               | 0.765  | 0.576   | 1.328           |
| 4               | 1.792  | 1.954   | 0.917           |
| 8               | 3.573  | 4.294   | 0.832           |
| 16              | 6.771  | 8.302   | 0.815           |
| 32              | 13.199 | 17.507  | 0.753           |
| 64              | 28.468 | 34.396  | 0.827           |
| 128             | 53.476 | 46.242  | 1.156           |
| 256             | 91.285 | 83.171  | 1.097           |
| 512             | 466.15 | 294.25  | 1.584           |
| 1024            | 385.61 | 304.31  | 1.267           |
| 2048            | 758.55 | 587.89  | 1.290           |

Kayaknya nanti bisa dipertimbangin deh mau make jenis proses yang mana, tergantung jumlah populasinya. Hmm kira2 bisa ngga ini diterapin di fungsi fitness. Di versi kode sebelumnya sebenernya lebih lama di ngurusin perhitungan fitness-nya, kalo generate population mah cuman diawal doang.

Selanjutnya kita fokus ke step selanjutnya .. . 

Eh selanjutnya fitness function, dan gw udah ada fitness function manager yang ngurus berbagai fitness function di dalem satu kelas, dan kayaknya ini lebih fleksibel. Kalo yang dulu kan semua fungsi fitness langsung dimasukin kedalam satu kelas, jadi bakal susah dimodifikasi. Hmm, keknya ribet kalo dibayangin penjelasan gw, ini kodenya:

```python
class FitnessFunction:
    def __init__(self, all: bool = True):
        self.minimize_conflicts = None
        self.maximize_resource_utilization = None
        self.participant_availability = None
        self.all = all

        # MaximizeResourceUtilization Parameters
        self.max_groups_per_assistant = 2
        self.max_shift_per_assistant = 16

    def initialize(self):
        self.minimize_conflicts = MinimizeConflicts()
        self.maximize_resource_utilization = MaximizeResourceUtilization(self.max_groups_per_assistant, self.max_shift_per_assistant)
        self.participant_availability = ParticipantAvailability(GroupData())
    
    def calculate_all_fitness(self, chromosome: Chromosome):
        fitness = []
        fitness.append(self.minimize_conflicts.calculate_fitness(chromosome))
        fitness.append(self.maximize_resource_utilization.calculate_fitness(chromosome))
        fitness.append(self.participant_availability.calculate_fitness(chromosome))
        return sum(fitness)

    
    def calculate_fitness(self, chromosome: Chromosome):
        if settings.DEBUG:
            logger.info(f"Calculating fitness for chromosome {chromosome}")
        fitness = self.calculate_all_fitness(chromosome)
        return fitness
```

Kalo dari sini, tiap settingan fungsi fitness diatur via kelas ini, jadi kalo ada kelas fitness baru bakal ribet, dan bakal overwhelmed si kodinger-nya. Satu kelass ada banyak properti yang mesti diatur, bakal pusing kan? Nah ini kode barunya:

```python
#Fitness Manager
class FitnessManager:
    def __init__(self, fitness_functions: List[BaseFitness]):
        self.fitness_functions = fitness_functions
    
    def __str__(self):
        return f"FitnessManager(fitness_functions={self.fitness_functions})"
    
    def __repr__(self):
        return self.__str__()
    
    def __call__(self, chromosome: Chromosome):
        return sum([fitness_function(chromosome) for fitness_function in self.fitness_functions])
    
    def configure(self, fitness_functions: List[BaseFitness]):
        self.fitness_functions = fitness_functions

    def grouped_fitness(self, chromosome: Chromosome):
        """Return a dictionary of fitness functions and their respective fitness value"""
        return {fitness_function.name: fitness_function(chromosome) for fitness_function in self.fitness_functions}
```

Jadi lebih simpel, tugas kelas ini cuman ngumpulin fungsi2 fitness yang udah dibikin sebelumnya kedalam satu kelas, jadi setelah dikumpulin tinggal panggil kelas ini aja. Begini contoh penggunannya:

```python
group_assignment_conflict_fitness = GroupAssignmentConflictFitness()
assistant_distribution_fitness = AssistantDistributionFitness()

assistant_distribution_fitness.configure(15, 15, 1, 1)
group_assignment_conflict_fitness.configure(2, 1)

fitness_manager = FitnessManager([group_assignment_conflict_fitness, assistant_distribution_fitness])

fitness_manager(population[0])
```

Lebih simpel jadinya.

Tapi bisa juga sih cukup manggil population.calculate_fitness(), soalnya di bagian pembangunan populasi langsung otomatis dimasukin fungsi fitness kedalam tiap populasi, walau belum dinamis sih, masih hardcoded di kelas Factory(). Ini kodenya:

```python
class Factory:
    def __init__(self):
        self.laboratories = LaboratoryData.get_laboratories()
        self.modules = ModuleData.get_modules()
        self.chapters = ChapterData.get_chapters()
        self.groups = GroupData.get_groups()
        self.participants = ParticipantData.get_participants()
        self.assistants = AssistantData.get_assistants()
        self.constant = Constant
        
        self.constraints = ConstraintManager([ChapterModuleConstraint(), GroupModuleConstraint(), ModuleLaboratoryConstraint(), AssistantLaboratoryConstraint(), ScheduleConstraint()])
        self.fitness_manager = FitnessManager([GroupAssignmentConflictFitness(), AssistantDistributionFitness()])
		
	#other code
	
	def generate_population(self, population_size: int) -> Population:
        """Generate a population based on the population size"""
        chromosomes = []
        for i in range(population_size):
            chromosomes.append(self.generate_chromosome())

        population = Population(chromosomes, self.fitness_manager)
        #population.calculate_fitness()
        return population
```

Hmmm berarti ngga perlu bikin lagi kan ya??? Berarti tinggal lanjut aja kan yaa? Mungkin nanti2, bakal bisa tambahin fitness function sendiri. Berarti bisa moveon ke operator.

Hmmm udah sampe fungsi mutation, sebenernya rada bingung sih, pas generate chromosome, apa mending masukin id aja, atau sekalian sama objeknya ya? Tapi performanya sejauh ini ngga jauh beda sih ama kalo masukin id doang, apa coba dulu? Paling cuman beda pas generate di awal aja, kalo masukin seluruh objek setidaknya jadi mempermudah buat cek and ricek segalanya. Ngga perlu pusing2 manggil data berbasiskan id lagi.

Wait, chat gpt memberikan solusi yang lebih baik, yaitu dengan menggunakan metode hybrid. Jadi yang di store di gene cukup id-nya aja, tapi ketika butuh data lengkapnya, bisa manggil property yang ada di dalam gene-nya. Awalnya gw cuman berasumsi di dalem gene cuman perlu id doang.

Senernya setelah diitung2, mau pake id doang atau sekalian objek, pas generate populasinya sama2 aja sih. Tapi mungkin bakal jadi beban memori kalo kebanyakan. Baiklah kita coba hybrid aja.

--------------------

Baiklah sudahhh, sekarang gene cuman diisi id doang, tapi ketika data lengkapnya dibutuhin, si gene bisa tinggal manggil aja. Dulu rada pusing dan ribet kalo semisal butuh data lab dari gene, tapi di gene cuman ada id nya doang, bakal ribet kalo mesti manggil kelasnya dulu.
Fungsi mutasi juga udah kelar, sekarang tinggal lanjut ke fungsi crossover mungking.

Keknya crossover juga udah.

------------------

hmmm fungsi generate_time_slot banyak dipake, keknya mending dibikin fungsi umum deh,
fungsi ini:
```python
def generate_time_slot(self, start_date, end_date):
        """Generate time slots based on the start date, end date, days and shifts"""
        #if start_date not start from Monday, then start from the next Monday
        if start_date.weekday() != 0:
            start_date = start_date + timedelta(days=7 - start_date.weekday())
        duration = (end_date - start_date).days + 1
        weeks_duration = floor(duration / 7)
        random_weeks = np.random.randint(0, weeks_duration)
        random_days = np.random.choice(Constant.days)
        random_shifts = np.random.choice(Constant.shifts)
        random_date = start_date + timedelta(days=random_weeks * 7 + Constant.days.index(random_days))
        return TimeSlot(random_date, random_days, random_shifts)
```

Tapi nanti aja deh, pas bagian rapihin.

hmmmmm, repair keknya udah? dan kok kayak lebih cepet ya.
Tapi masih bingung sih, deepcopy fungsinya buat apaan ya, gw tau sih itu buat apa, tapi apakah perlu gitu di beberapa kode gw? keknya gw mesti pelajarin kira2 bagian mana aja yang perlu deepcopy.

--------------------------------

Wih selection tau2 udah, dan lancar? Berarti lanjut ke genetika algoritma dong.

-------------------------------=

damn, kodingnya bisa run, dan kayaknya ngga ada yang error. tapi gw malah ketemu permasalahan baru, di iterasi pertama kode-nya bisa run dengan lancar, tapi buat step selanjutnya malah makin slow dan perlahan crashing, apakah masalah memory? gw cek juga ngga ada loop yang bermasalah. gw juga belum nerapin proses pararel. keknya emang memori deh, soalnya itu yang berubah drastis juga sih.

hmm, ternyata karena masalah print data terlalu banyak, ngga ngeh kalo 1 populasi aja bisa ratusan ribu karakter, di word aja langsung full 60 halaman, apalagi kalo diprint berkali2.

----------------------------

Sekarang udah ngga crash sih, tapi prosesnya masih lamaa banget. Kenapa ya, kok bisa lebih lama dari sebelumnya? Kemungkinan ada di pemanggilan database, dan deepcopy sih. Rada lama nunggunya dan sekarang gw udah ngantuk banget . . .

Lanjut besok kali ya,
Ini hasil dari profiler. Beberapa baris pertama sih, 
```
413357878 function calls (389642981 primitive calls) in 921.584 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   449224  239.162    0.001  245.420    0.001 {method 'execute' of 'psycopg2.extensions.cursor' objects}
11884824/726   29.727    0.000   70.469    0.097 copy.py:128(deepcopy)
  1084892   14.404    0.000  638.076    0.001 query.py:85(__iter__)
715671/449224   13.309    0.000   93.602    0.000 query.py:1361(build_filter)
18740225/18199575   12.976    0.000   29.253    0.000 {built-in method builtins.getattr}
   449224   11.340    0.000  180.953    0.000 compiler.py:725(as_sql)
   449224   11.165    0.000   70.335    0.000 compiler.py:229(get_select)
2070637/716397   10.488    0.000   78.472    0.000 copy.py:259(_reconstruct)
   635668   10.132    0.000   19.568    0.000 base.py:460(__init__)
   807022    8.998    0.000   16.131    0.000 query.py:314(clone)
  5131498    8.695    0.000   15.606    0.000 compiler.py:519(quote_name_unless_alias)
715671/449224    8.130    0.000  112.037    0.000 query.py:1556(_add_q)
3688809/2790361    7.573    0.000   83.161    0.000 compiler.py:541(compile)
 19556846    7.495    0.000   10.721    0.000 {built-in method builtins.isinstance}
   449224    7.275    0.000  497.120    0.001 compiler.py:1532(execute_sql)
   449224    7.131    0.000   24.283    0.000 compiler.py:950(get_default_columns)
   898446    7.128    0.000   18.725    0.000 compiler.py:2093(<lambda>)
 32953499    6.837    0.000    6.837    0.000 {method 'get' of 'dict' objects}
   286283    6.833    0.000    6.833    0.000 decoder.py:343(raw_decode)
   898448    6.359    0.000    7.821    0.000 query.py:1652(names_to_path)
   863917    6.250    0.000   23.609    0.000 copy.py:66(copy)
  2341137    6.201    0.000   11.906    0.000 __init__.py:492(get_col)
  4046607    6.043    0.000   21.810    0.000 {method 'join' of 'str' objects}
   450669    5.745    0.000  644.288    0.001 query.py:1879(_fetch_all)
712064/726    5.555    0.000   70.433    0.097 copy.py:227(_deepcopy_dict)
 15495552    5.506    0.000    5.506    0.000 {built-in method builtins.hasattr}
  2341137    5.389    0.000   25.336    0.000 expressions.py:1130(as_sql)
   540650    5.374    0.000   10.389    0.000 local.py:44(_get_context_id)
   449223    5.349    0.000   20.237    0.000 compiler.py:1483(get_converters)
   449224    5.292    0.000   11.950    0.000 query.py:1768(setup_joins)
  2883152    5.210    0.000    7.017    0.000 __init__.py:615(__eq__)
  1891910    4.934    0.000   14.366    0.000 expressions.py:1146(get_db_converters)
   357798    4.750    0.000  613.947    0.002 query.py:613(get)
   807022    4.723    0.000   25.609    0.000 query.py:1860(_clone)
   449224    4.623    0.000   37.240    0.000 lookups.py:213(process_lhs)
1581489/1433243    4.587    0.000    9.818    0.000 {method '__reduce_ex__' of 'object' objects}
    89570    4.476    0.000  836.688    0.009 1329345222.py:221(get_schedule)
```

Kalo dari total time rada keliatan kalo yang panjang2 berkaitan database, dan deepcopy. Tapi ketika diliat via cumtime, jelas banget semua yang berkaitan ama database yang paling panjanggg. Keknya itu yang mesti dioptimasiin, masih ngga paham cara biar efisiennya gimana. Liat sendiri tuh, total cumulative time get_schedule sebanyak itu . . .

hmm, ribet juga ya, ini bukan masalah logika tapi struktur dan karakteristik pemrosesan data di python ...

Lanjut besokk dahh.